
PRODUCT REQUIREMENTS DOCUMENT
FDE Sidekick
AI-Powered Hackathon Companion

Version
0.1.0 (MVP)
Author
Sughu
Date
February 28, 2026
Status
Draft
Repository
github.com/sughu/fde-sidekick

Table of Contents



Executive Summary
FDE Sidekick is a real-time AI companion for hackathon teams. It listens to a team’s conversation—via text or voice—and continuously generates living artifacts: architecture diagrams, session summaries, product requirements documents, and prototype code scaffolds. The tool transforms unstructured brainstorming into structured, actionable deliverables without breaking the team’s conversational flow.
The product targets hackathon participants, developer advocates, FDEs, and solution architects who need to move from ideation to implementation rapidly. It is designed as an open-source project for GitHub distribution with a Twitter-first launch strategy.
Problem Statement
Hackathon teams consistently face the same bottleneck: the gap between verbal brainstorming and structured documentation. Teams spend their first 1–2 hours talking through ideas, only to realize they have no written record of decisions, no architecture diagram, and no shared document to align on scope.
Current Pain Points
	•	Brainstorming sessions produce ideas but no artifacts—decisions evaporate after the conversation ends.
	•	Architecture diagrams are drawn on whiteboards that can’t be version-controlled or shared digitally.
	•	Someone must stop building to write the PRD, splitting the team’s focus during the most time-pressured phase.
	•	Team members who join late or miss parts of the discussion have no way to catch up on context.
	•	Prototype scaffolding (project structure, boilerplate, API stubs) is created from scratch every time.
Opportunity
LLMs can now process conversational input and produce structured outputs in real-time. By embedding an AI agent directly into the hackathon workflow, we eliminate the documentation bottleneck entirely—turning every conversation into a living, auto-updating project plan.

Goals and Non-Goals
Goals
	•	G1: Zero-friction documentation. Every message the team sends should automatically update all relevant artifacts without requiring manual triggers or separate prompts.
	•	G2: Visual impact for social distribution. The UI must be visually striking enough to generate engagement in a 30–60 second Twitter video demo. The Factory/Droid design language (true black, terminal green, monospace) ensures differentiation.
	•	G3: Extensible artifact system. New artifact types (timeline, risk matrix, sprint plan) can be added by appending a single object to a registry array—no architectural changes required.
	•	G4: Open-source GitHub launch. Clean single-file React component, comprehensive README with setup instructions, and MIT license for maximum adoption.
Non-Goals (v0.1)
	•	Multi-user collaboration (single session only)
	•	Persistent storage or conversation history across sessions
	•	Backend server—v0.1 is a pure client-side application calling the Anthropic API directly
	•	Mobile-optimized layout (desktop-first for v0.1)
	•	Custom model selection (hardcoded to Claude Sonnet)

User Personas
Persona
Description
Primary Need
Success Metric
Hackathon Team Lead
Technical lead running a 24–48 hour hackathon project with 2–5 teammates
Align team on scope and architecture without losing build time
Zero time spent writing docs manually
FDE / Solutions Architect
Field engineer running customer demos or POC workshops
Generate professional-looking architecture and PRD artifacts during live sessions
Artifacts ready to share with stakeholders within minutes
Solo Hacker
Individual developer brainstorming a side project or startup idea
Externalize thinking into structured documents to validate feasibility
Complete PRD and prototype scaffold from 10 minutes of conversation
Developer Advocate
DevRel professional creating demo content for conferences or social media
Produce visually compelling AI demos that showcase tool capabilities
Twitter-worthy video clip in under 60 seconds

Feature Specification
Conversational Interface
The chat panel occupies the left 33% of the viewport. It supports both keyboard text input and browser-native speech recognition via the Web Speech API.
Text Input
	•	Monospace input field with terminal-style green prompt indicator (›).
	•	Send on Enter; Shift+Enter for newline (future).
	•	Input is disabled during API processing to prevent race conditions.
Voice Input
	•	Toggle microphone via dedicated button (circle ● for record, square ■ for stop).
	•	Uses SpeechRecognition API (Chrome/Edge) with continuous=true and interimResults=true.
	•	Live waveform animation and elapsed time counter displayed during recording.
	•	Interim transcription populates the input field in real-time; final transcript commits on stop.
Follow-Up Suggestions
After each assistant response, 2–3 follow-up questions are rendered as clickable chips below the chat. Clicking a chip sends it as the next user message, enabling rapid conversational depth without typing. Chips are disabled during processing.
Artifact System
The artifact panel occupies the right 67% of the viewport, divided into two stacked panels. Each panel displays one artifact type. Users can swap any panel to a different artifact type via the ⇅ control in the panel header.
Artifact Types (v0.1 Registry)
ID
Label
Description
Renderer
Output Format
diagram
ARCH
System architecture / workflow visualization
Mermaid.js
Mermaid graph TD syntax
summary
SUM
Running session summary with key decisions and open questions
Markdown
Structured markdown
prd
PRD
Auto-generated product requirements document
Markdown
Markdown with tables
prototype
CODE
Key code scaffolds using real frameworks
Markdown
Markdown with code blocks

Extensibility
New artifact types are added by appending an object to the ARTIFACT_TYPES array. The system prompt is auto-generated from this registry, so the LLM will immediately begin producing content for any new type. No other code changes are required.
Auto-Switch Behavior
When an API response updates an artifact that is not currently visible in either panel, the system automatically swaps it into the second (bottom) panel. A green-bordered flash animation and “LIVE” badge appear for 2 seconds to draw attention to the update. If multiple artifacts update in a single response, they cascade with 500ms staggered reveals.
5-Minute Huddle Mode
Huddle mode activates a 5:00 countdown timer in the header and modifies the system prompt to push for decisive, structured output. The AI becomes more opinionated and focused on concrete decisions: scope definition, role assignment, timeline planning, and critical path identification. The mode ends automatically when the timer reaches zero or when manually stopped.

Technical Architecture
System Overview
FDE Sidekick v0.1 is a single-file React component with no backend. The client communicates directly with the Anthropic Messages API. All state is held in React hooks; there is no persistent storage.
Data Flow
	•	User submits a message (text or voice transcription).
	•	Full conversation history is sent to Claude Sonnet via the Messages API.
	•	The system prompt instructs Claude to return a JSON object containing: conversational response, follow-up questions, and all artifact content.
	•	The client parses the JSON and updates React state for each artifact.
	•	Auto-switch logic detects which artifacts changed and updates the visible panels.
	•	Mermaid.js renders the diagram artifact; markdown renderer handles the rest.
Tech Stack
Layer
Technology
Notes
Frontend Framework
React (single-file JSX)
No build step required when used as a Claude artifact
LLM Provider
Anthropic Claude Sonnet
Via Messages API, structured JSON output
Diagram Rendering
Mermaid.js 10.6.1
CDN-loaded, dark theme, custom color variables
Voice Input
Web Speech API
Chrome/Edge only; continuous + interim results
Typography
IBM Plex Mono
Google Fonts CDN; monospace-only design
Styling
Inline styles + CSS animations
No Tailwind dependency; self-contained
API Contract
Every user message triggers a single API call. The system prompt instructs Claude to return a JSON object with the following schema:
Field
Type
Description
response
string
The conversational reply shown in the chat panel
followUpQuestions
string[]
2–3 targeted questions rendered as clickable chips
diagram
string
Complete Mermaid graph TD syntax with style lines
summary
string
Markdown session summary (project, decisions, open questions)
prd
string
Markdown PRD (overview, goals, user stories, tech requirements)
prototype
string
Code scaffolds in markdown with fenced code blocks

Design Language
The visual identity follows the Factory/Droid design system: a terminal-native aesthetic built for developer tools.
Design Principles
	•	True black, not dark gray. Background is #050505. Borders are #111 and #151515. No gradients, no glow effects, no noise textures. The UI disappears so the content can speak.
	•	Terminal green as the sole accent. #22C55E for active states, labels, and indicators. #4ADE80 for interactive elements. No secondary accent colors.
	•	Monospace everywhere. IBM Plex Mono at all sizes. This is a developer tool—every pixel should feel like a terminal.
	•	Minimal chrome. No rounded corners beyond 6px. No shadows. No decoration. Borders, type, and whitespace only.
	•	Information density over visual comfort. The UI is dense by design—hackathon teams need maximum information in minimum space.
Color Palette
Token
Hex
Usage
bg-primary
#050505
Application background
bg-surface
#0A0A0A
Panels, cards, artifact containers
bg-elevated
#0D0D0D
Chat bubbles, input fields
border-default
#111111
Primary borders
border-subtle
#151515
Secondary borders, dividers
accent-primary
#22C55E
Labels, active states, status dots
accent-bright
#4ADE80
Interactive elements, follow-up chips
text-primary
#CCCCCC
User messages, primary content
text-secondary
#777777
Assistant messages, body copy
text-muted
#333333
Placeholders, disabled states
danger
#EF4444
Huddle mode, recording state
Layout Specification
Region
Dimensions
Contents
Header
100% x 40px
Logo, product name, version badge, huddle control, artifact counter
Chat Panel
33% width
Message history, follow-up chips, text/voice input bar
Artifact Panel
67% width
Two stacked panels, each with header + swappable content
Status Bar
100% x 22px
Connection status, message count, huddle indicator, GitHub link

Launch Plan
Distribution Strategy
FDE Sidekick launches as an open-source GitHub repository with a Twitter-first social strategy. The goal is to demonstrate the tool’s capabilities through a compelling video demo that showcases real-time artifact generation.
GitHub Repository Structure
	•	fde-sidekick.jsx — Single-file React component (the entire application)
	•	README.md — Setup instructions, architecture explanation, extensibility guide, GIF embed
	•	demo.gif — Recorded demo for the README hero section
	•	LICENSE — MIT
Twitter Video Demo Plan
The demo video should be 30–60 seconds, captured at high resolution, showing a single continuous interaction where the user describes a project and artifacts populate in real-time. Key moments to capture:
	•	First message triggers architecture diagram rendering in the top panel.
	•	Follow-up response updates summary in the bottom panel simultaneously.
	•	Auto-switch animation fires when PRD content populates for the first time.
	•	Huddle mode activation with countdown timer visible.
	•	Voice input with waveform animation (if browser supports it).

Future Roadmap
v0.2 — Polish & Export
	•	Export all artifacts as a downloadable ZIP (markdown + mermaid files).
	•	Conversation replay/playback mode for demo creation.
	•	Improved Mermaid diagram styling with interactive zoom and pan.
	•	Session persistence via browser state (in-memory, not localStorage).
v0.3 — Multi-User & Integrations
	•	WebSocket-based multi-user sessions for team collaboration.
	•	GitHub integration: auto-create repo from prototype scaffold.
	•	Slack/Discord bot mode for running Sidekick inside team channels.
	•	Model selection (Claude, GPT, Gemini) with per-artifact model routing.
v1.0 — Platform
	•	Custom artifact plugins (community-contributed renderers).
	•	Persistent project workspace with version history.
	•	Enterprise features: SSO, audit logging, private model deployment.
	•	Mobile-responsive layout for on-the-go hackathon management.
Success Metrics
Metric
Target
Measurement
GitHub Stars (30 days)
500+
GitHub repo analytics
Twitter Video Views
50,000+
Twitter analytics on launch post
Twitter Engagement Rate
>5%
Likes + retweets + replies / impressions
Fork-to-Star Ratio
>10%
Indicates developers actively building on it
Time to First Artifact
<30 seconds
From first message to diagram rendering
Artifact Quality (subjective)
Demo-ready
Artifacts usable without manual editing

Risks and Mitigations
Risk
Severity
Mitigation
API key exposure in client-side code
High
Document that users must use their own key; recommend env proxy for production use. v0.2 adds optional backend proxy.
JSON parsing failures from LLM
Medium
Fallback: display raw response as chat message; retry logic with simplified prompt on parse error.
Speech recognition browser support
Medium
Graceful degradation: hide mic button on unsupported browsers; text input always available.
Mermaid rendering errors
Low
Fallback: display raw Mermaid syntax as monospace text; user can copy-paste into mermaid.live.
Rate limiting on Anthropic API
Medium
Client-side debouncing; batch artifact updates; display clear error messaging.

Appendix: Adding Custom Artifacts
The artifact system is registry-driven. To add a new artifact type, append an object to the ARTIFACT_TYPES array at the top of the component file:
const ARTIFACT_TYPES = [
  // ...existing types
  {
    id: "timeline",
    label: "TIME",
    fullLabel: "Timeline",
    icon: "⏱",
    promptKey: "timeline",
    desc: "Gantt-style project timeline"
  },
];
The system prompt is auto-generated from this registry. Claude will immediately begin producing content for the new artifact type in its JSON responses. No changes to the rendering pipeline, auto-switch logic, or panel system are required.
